\section{Conclusions}\label{sec: conclusion}
We build on the connection to {\em data provenance} to develop a model for  data citation which is able to handle aggregate queries and views. The model reasons about citations at the level of tuples in the query result using provenance to enable citations to arbitrary subsets of the query result (fine-grained citation).  The \pbafull\ was implemented in \provalg, which runs on top of a provenance-enabled RDBMS.  Extensive experiments were conducted under both {\em synthetic} and {\em realistic workloads}, and show that \provalg\ can not only handle a {larger class of queries} than the Rewriting-Based Model~\cite{wu2018data} (which assumes conjunctive queries and views), but is much faster in some cases.   

Optimizations used in \provalg\ include materializing view provenance, 
%(the {\em eager} versus {\em lazy} strategy), 
building an index %over query provenance 
to speed up comparisons between the query and view provenance, using bit arrays, and using clustering algorithm to determine the best order of combining view mappings.
Several of these are applicable in other scenarios where the provenance from different queries or views needs to be compared, such as fine-grained access control \cite{goyal2006attribute} and linked brushing in data visualization \cite{psallidas2018smoke}.
%to represent covering set and the subgoals and aggregate terms it covers

In future work, we would like to explore how to insert data citation into the larger citation ecosystem involving bibliometrics. We would also like to explore how to combine data citation with black-box computations, including Machine Learning models. 

\eat{
This is the first paper to build a {\em \pbafull} to connect the notion of {\em data citation} and {\em data provenance}, which is able to handle a larger class of queries and views i.e. aggregate queries and views compared to previous work and generate citations for query result at \textit{various granularity}. Efficient implementations for provenance reasoning, \provalg, are challenging but achieved by utilizing various optimization strategies. In \provalg, two different strategies are designed to deal with the provenance of views, which is either precomputed ({\em eager strategy}) or computed on the fly ({\em lazy strategy}). 

Extensive experiments are conducted under both {\em synthetic workloads} and {\em realistic workloads}. The experimental results justify the feasibility of \provalg\ to this model, which is not only powerful but also much faster in some cases compared to the implementations of \rba. Besides, the trade-offs between {\em eager strategy} and {\em lazy strategy} has been explored. The choice depends on users' preferences for speed or less space in practice.

In future work, we would like to explore how to integrate data citation into a larger citation ecosystem, which aims at efficiently and accurately computing and monitoring contributors' bibliometrics. Plus, considering the fact that machine learning algorithms are widely used and cited in {\em data science environment} and machine learning model is a special aggregate function, it will be also an interesting extension to automate citation generation process for machine learning pipeline.}